# 有用的资料
http://mocom.xmu.edu.cn/article/show/586279a4aa2c3f280956e7ad/0/1 厦门大学奇异值SVD分解

# 线性代数

## 相似矩阵
```
同济大学 《线性代数》 P124-推论
```

若n阶矩阵A与对角矩阵相似$\Lambda$，

$\Lambda=\left[\begin{array}{ccc}\lambda_1&&& \\  & \lambda_2&& \\ &&...&\\ &&&\lambda_n \end{array}\right]$


则$\lambda_1,\lambda_2,\lambda_3,...,\lambda_n$是A的n个特征值。


# 笔记
1. 为什么要引入奇异矩阵分解?

对于m个样本，每个样本有n个属性的训练数据$A_{mxn}$,
当m=n相等时，A为n阶方阵，可以通过特征值和特征向量对矩阵进行分解

$A=Q_{nxn}\sum_{nxn} Q_{nxn}^{-1}$

Q是特征向量组成的矩阵，$\sum$是特征值降序构成的对角矩阵.
可以通过在$\sum$和Q中删去那些较小的特征值和对应的特征向量，达到姜维效果

问题A很小情况下满足N阶方阵，可以将A分解为三部分


$A=U_{mxk}\sum_{kxk} Q_{kxn}^{-T}$

其中U、V是两个正交矩阵，其中的每一行（每一列）分别被称为 左奇异向量 和 右奇异向量，他们和 Σ中对角线上的奇异值相对应，通常情况下我们只需要取一个较小的值k，保留前k
个奇异向量和奇异值即可，其中U的维度是m×k、V的维度是n×k、Σ是一个k×k的方阵，从而达到降维效果。

### 奇异值怎么求？
我还不知道？
大概是 $A*A^T$或者$A^T*A$的特征值？
http://twogen.cn/c/50.html